{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Using XLNet and 20-Newsgroup Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLNetTokenizer, TFXLNetLMHeadModel, TFXLNetForMultipleChoice\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check available gpu. Just in case, always good to see if CUDA is integrating properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name: \n",
    "    print(device_name)\n",
    "\n",
    "else:\n",
    "   print(\"GPU not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train, val, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes')) #recommended setting for text classificaiton.\n",
    "test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes')) #removes noise from actual text.\n",
    "print(train.filenames.shape)\n",
    "print(test.filenames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a way I can reduce file amount easily while keeping the data stratified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_class, val_class = train_test_split(train.data, train.target, test_size=.90, stratify=train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_class, val_class = train_test_split(train_data, train_class, test_size=.25, stratify=train_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, _, test_class, _ = train_test_split(test.data, test.target, test_size=.95, stratify=test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at sample. We can see the excess headers, subject lines, and emails have been removed\n",
    "\n",
    "Now we can use only the text to create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the proportions are indeed similar across train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(train_class, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "unique, counts = np.unique(val_class, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "\n",
    "plt.title('Class Frequency')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         if key == \"token_type_ids\":\n",
    "#             print(arr[:, :-1])\n",
    "#             arr = tf.concat([arr[:, :-1], tf.zeros([1,missing_pad_len], tf.int32)], 1)\n",
    "#             new_class_tf.constant([[2]], dtype=tf.int32)\n",
    "#             arr = tf.concat([arr, tf.constant([[2]], dtype=tf.int32)])\n",
    "#         else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(arr, max_len):\n",
    "    arr_len = len(arr)\n",
    "    missing_pad_len = max_len - arr_len\n",
    "    arr = arr + ([0] * missing_pad_len)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(arr, dtype=tf.int32):\n",
    "    out_tensor = tf.squeeze(tf.convert_to_tensor(arr, dtype=dtype))\n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_dict(input_ids, attention_mask, token_type_ids):\n",
    "  return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"attention_mask\": attention_mask,\n",
    "      \"token_type_ids\": token_type_ids,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function for encoding data into the correct format for XLNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data, max_len, batch_size):\n",
    "    input_ids = []\n",
    "    token_type_ids = []\n",
    "    attention_mask = []\n",
    "    \n",
    "    tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)  # no lower case native model.\n",
    "    batch_count=0\n",
    "    for i, news in enumerate(data):\n",
    "        id_batch = []\n",
    "        token_batch = []\n",
    "        attention_batch = []\n",
    "        encoded_data = tokenizer.encode_plus(news,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=max_len,\n",
    "                                            truncation=True,\n",
    "                                            return_token_type_ids=True,\n",
    "                                            return_attention_mask=True)\n",
    "        \n",
    "\n",
    "        padded_ids = pad_data(encoded_data['input_ids'], max_len)  # need so that padding is appended to end of vector.\n",
    "        id_batch.append(padded_ids)\n",
    "        \n",
    "        padded_token_type = pad_data(encoded_data['token_type_ids'], max_len)\n",
    "        token_batch.append(padded_token_type)\n",
    "        \n",
    "        padded_attention = pad_data(encoded_data['attention_mask'], max_len)\n",
    "        attention_batch.append(padded_attention)\n",
    "        \n",
    "        batch_count+=1\n",
    "        if batch_count == batch_size or i<=0:\n",
    "            input_ids.append(id_batch)\n",
    "            token_type_ids.append(token_batch)\n",
    "            attention_mask.append(attention_batch)\n",
    "            batch_count=0\n",
    "    tensor_dataset = [to_tensor(input_ids), to_tensor(attention_mask), to_tensor(token_type_ids)]\n",
    "#     tensor_dataset = tf.data.Dataset.from_tensor_slices((input_ids,\n",
    "#                                                           attention_mask,\n",
    "#                                                           token_type_ids))\n",
    "    return tensor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XLNet_max_len = 300\n",
    "batch_size = 4  # batch size and max len taken from https://github.com/zihangdai/xlnet#:~:text=For%20the%20best%20performance%2C%20XLNet,with%20GPUs%20is%20quite%20difficult.\n",
    "encoded_train = encode_data(train_data, XLNet_max_len, batch_size)\n",
    "encoded_val = encode_data(val_data, XLNet_max_len, batch_size)\n",
    "encoded_test = encode_data(test.data, XLNet_max_len, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoded_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fine tuning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(train_enc, val_enc):  # could have used ktrain for all, but where's the fun in that ;)\n",
    "    \n",
    "    model = TFXLNetLMHeadModel.from_pretrained('xlnet-base-cased')  # using this model to just create langauge model (LM).\n",
    "#     l_rate = 3e-5\n",
    "#     n_epochs = 2\n",
    "    \n",
    "    model = model(input_ids=train_enc[0], attention_mask=train_enc[1], token_type_ids=train_enc[2])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fine_tune_model(encoded_train, encoded_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftrans",
   "language": "python",
   "name": "tftrans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
